{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN4/i5nAixhuXZFXgg/UpQm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Levy Thiga Kariuki\n","import pandas as pd\n","import nltk\n","nltk.download('stopwords')\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import accuracy_score, classification_report\n","import re\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import learning_curve\n","import pickle\n","import seaborn as sns\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OKxJbehpztGb","executionInfo":{"status":"ok","timestamp":1702381400606,"user_tz":0,"elapsed":2870,"user":{"displayName":"Levy Kariuki","userId":"04295776132732464844"}},"outputId":"7aea85e0-d65e-496a-ba81-ed6ae6d84370"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["# Load the dataset\n","df = pd.read_csv('IMDB Dataset.csv')\n"],"metadata":{"id":"HqG90t7f1rrM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Text cleaning and preprocessing\n","def clean_text(text):\n","    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n","    text = text.lower()  # Convert to lowercase\n","    return text\n","\n","\n","df['review'] = df['review'].apply(clean_text)"],"metadata":{"id":"eUBTZQTF1vV7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)\n"],"metadata":{"id":"hqSV0DR2105n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a pipeline for text classification with TfidfVectorizer and K Neighbors Classifier\n","text_clf = Pipeline([\n","    ('tfidf', TfidfVectorizer(stop_words=stopwords.words('english') + list(ENGLISH_STOP_WORDS))),\n","    ('clf', KNeighborsClassifier()),\n","])\n"],"metadata":{"id":"K-u42Rtz15Sr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define hyperparameters for grid search\n","param_grid = {\n","    'tfidf__ngram_range': [(1, 1), (1, 2)],  # Unigrams or bigrams\n","    'clf__n_neighbors': [3, 5, 7],  # Number of neighbors\n","}\n"],"metadata":{"id":"6h776AXQ19s8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Perform grid search for hyperparameter tuning\n","grid_search = GridSearchCV(text_clf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n"],"metadata":{"id":"DNEmIntu2EaT"},"execution_count":null,"outputs":[]}]}