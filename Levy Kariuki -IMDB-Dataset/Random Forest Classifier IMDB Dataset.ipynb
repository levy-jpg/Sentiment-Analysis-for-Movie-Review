{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOiDWxUmqIe8emd2tHDm3oV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jptrcz2KVQ3l"},"outputs":[],"source":["#Levy Thiga Kariuki\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import accuracy_score, classification_report\n","import re\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import learning_curve\n","\n","# Load the dataset\n","df = pd.read_csv('IMDB Dataset.csv')\n","\n","# Text cleaning and preprocessing\n","def clean_text(text):\n","    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n","    text = text.lower()  # Convert to lowercase\n","    return text\n","\n","df['review'] = df['review'].apply(clean_text)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)\n","\n","# Create a pipeline for text classification with TfidfVectorizer and Random Forest Classifier\n","text_clf = Pipeline([\n","    ('tfidf', TfidfVectorizer(stop_words=stopwords.words('english') + list(ENGLISH_STOP_WORDS))),\n","    ('clf', RandomForestClassifier(random_state=42)),\n","])\n","\n","# Define hyperparameters for grid search\n","param_grid = {\n","    'tfidf__ngram_range': [(1, 1), (1, 2)],  # Unigrams or bigrams\n","    'clf__n_estimators': [50, 100, 200],\n","    'clf__max_depth': [None, 10, 20, 30],\n","}\n","\n","# Perform grid search for hyperparameter tuning\n","grid_search = GridSearchCV(text_clf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n","\n","# Print the best hyperparameters from the grid search\n","print(\"Best Hyperparameters:\", grid_search.best_params_)\n","\n","# Evaluate the performance on the test set\n","y_pred = grid_search.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy:.4f}')\n","\n","# Display classification report\n","print(classification_report(y_test, y_pred))\n","\n","# Plot learning curve\n","train_sizes, train_scores, test_scores = learning_curve(grid_search.best_estimator_, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n","\n","plt.figure(figsize=(10, 6))\n","plt.plot(train_sizes, train_scores.mean(axis=1), label='Training Accuracy')\n","plt.plot(train_sizes, test_scores.mean(axis=1), label='Validation Accuracy')\n","plt.title('Learning Curve')\n","plt.xlabel('Training Examples')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()\n"]}]}